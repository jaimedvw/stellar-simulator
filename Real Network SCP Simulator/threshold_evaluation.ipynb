{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CALCULATE AVERAGE THRESHOLD IN STELLAR LATEST USED"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69e2f8dfe88bdde4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/ledger_logs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m pattern \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mneeded=(\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md+)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m needed \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlog_path\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     11\u001B[0m         m \u001B[38;5;241m=\u001B[39m pattern\u001B[38;5;241m.\u001B[39msearch(line)\n",
      "File \u001B[0;32m~/PycharmProjects/thesis-stellar-simulator/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'src/ledger_logs.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "log_path = 'src/ledger_logs.txt'\n",
    "pattern = re.compile(r\"needed=(\\d+)\")\n",
    "needed = []\n",
    "\n",
    "with open(log_path) as f:\n",
    "    for line in f:\n",
    "        m = pattern.search(line)\n",
    "        if m:\n",
    "            needed.append(int(m.group(1)))\n",
    "\n",
    "df_needed = pd.DataFrame({'needed': needed})\n",
    "avg_needed = df_needed['needed'].mean()\n",
    "\n",
    "display(df_needed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-08T13:06:34.794281Z",
     "start_time": "2025-06-08T13:06:34.718853Z"
    }
   },
   "id": "e5eac3b3ae735800",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Average 'needed' (minimum_quorum) across all checks: {avg_needed:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-08T13:06:34.792644Z"
    }
   },
   "id": "5b49c1c92d44fae9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_path = 'src/quorumset_05_06_2025.json'\n",
    "with open(json_path) as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "def flatten_list(inner):\n",
    "    result = []\n",
    "    for v in inner.get('validators', []):\n",
    "        result.append(v)\n",
    "    for sub in inner.get('innerQuorumSets', []):\n",
    "        result.extend(flatten_list(sub))\n",
    "    return result\n",
    "\n",
    "rows = []\n",
    "for entry in raw['nodes']:\n",
    "    pk = entry['publicKey']\n",
    "    qs = entry['quorumSet']\n",
    "    thr = qs['threshold']\n",
    "    all_ids = set(qs.get('validators', []))\n",
    "    for sub in qs.get('innerQuorumSets', []):\n",
    "        all_ids.update(flatten_list(sub))\n",
    "    peer_count = len(all_ids)\n",
    "    threshold_percent = thr / peer_count if peer_count > 0 else None\n",
    "    rows.append({\n",
    "        'node': pk,\n",
    "        'peer_count': peer_count,\n",
    "        'threshold': thr,\n",
    "        'threshold_percent': threshold_percent\n",
    "    })\n",
    "\n",
    "df_peers = pd.DataFrame(rows)\n",
    "avg_peers = df_peers['peer_count'].mean()\n",
    "avg_percent = df_peers['threshold_percent'].dropna().mean()\n",
    "\n",
    "display(df_peers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-08T13:06:34.794705Z"
    }
   },
   "id": "191f71483d83c0bd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Average number of unique peers per node: {avg_peers:.2f}\")\n",
    "print(f\"Average threshold as a fraction of peers: {avg_percent:.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-08T13:06:34.796364Z"
    }
   },
   "id": "3be92958a3487151",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_path = 'src/quorumset_05_06_2025.json'\n",
    "with open(json_path) as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "def flatten_list(inner):\n",
    "    # collect *validators* itself, but for slice-count we don't flatten deeper\n",
    "    return inner.get('validators', [])\n",
    "\n",
    "rows = []\n",
    "for entry in raw['nodes']:\n",
    "    pk = entry['publicKey']\n",
    "    qs = entry['quorumSet']\n",
    "    thr = qs['threshold']\n",
    "    top_validators    = len(qs.get('validators', []))\n",
    "    top_slices        = 1                           # the top-level slice itself counts as 1\n",
    "    inner_slices      = len(qs.get('innerQuorumSets', []))\n",
    "    total_slices      = top_slices + inner_slices\n",
    "    # what % of slices does JSON-threshold represent?\n",
    "    threshold_pct     = thr / total_slices if total_slices>0 else None\n",
    "\n",
    "    rows.append({\n",
    "        'node'             : pk,\n",
    "        'total_slices'     : total_slices,\n",
    "        'json_threshold'   : thr,\n",
    "        'threshold_percent': threshold_pct\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "print(f\"avg. slices/node = {df['total_slices'].mean():.1f}\")\n",
    "print(f\"avg. JSON threshold = {df['json_threshold'].mean():.1f}\")\n",
    "print(f\"avg. % of slices = {100*df['threshold_percent'].mean():.1f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-08T13:06:34.797268Z"
    }
   },
   "id": "3f43fc59ebb19999",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
