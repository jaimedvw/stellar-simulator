{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (1.25.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:45.450663Z",
     "start_time": "2025-03-16T18:08:44.546938Z"
    }
   },
   "id": "69be3bd04b03062e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_transaction_count(line):\n",
    "    pattern = r\"transactions = \\{([^}]+)\\}\"\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        return set(re.findall(r\"Transaction ([a-fA-F0-9]+)\", match.group(1)))\n",
    "    return set()\n",
    "\n",
    "def get_timestamp(line):\n",
    "    pattern = r\"^\\d+\\.\\d+\"\n",
    "    match = re.match(pattern, line)\n",
    "    return float(match.group(0)) if match else None\n",
    "\n",
    "def get_node_name(line):\n",
    "    pattern = r\"Node ([A-Z0-9]+)\"\n",
    "    match = re.search(pattern, line)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def count_unique_mempool_transactions(file_path, node_number):\n",
    "    unique_transactions = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if f\"Node {node_number}\" in line and \"from mempool\" in line:\n",
    "                unique_transactions.update(re.findall(r\"Transaction ([a-fA-F0-9]+)\", line))\n",
    "    return len(unique_transactions)\n",
    "\n",
    "\n",
    "def process_log_lines(file_path):\n",
    "    node_data = defaultdict(lambda: {\n",
    "        \"Timestamp of finalisation\": None, \n",
    "        \"Finalised transactions\": set(),  \n",
    "        \"Externalize messages\": []\n",
    "    })\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'appended SCPExternalize message to its storage and state' not in line:\n",
    "            continue\n",
    "        \n",
    "        node_name = get_node_name(line)\n",
    "        timestamp = get_timestamp(line)\n",
    "        transactions = get_transaction_count(line)\n",
    "        \n",
    "        if node_name:\n",
    "            if node_data[node_name][\"Timestamp of finalisation\"] is None:\n",
    "                node_data[node_name][\"Timestamp of finalisation\"] = timestamp\n",
    "            node_data[node_name][\"Finalised transactions\"].update(transactions)\n",
    "            node_data[node_name][\"Externalize messages\"].append(line.strip())\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(node_data, orient='index')\n",
    "    df.index.name = \"sequence number\"\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df[\"No. of finalised transactions\"] = df[\"Finalised transactions\"].apply(len)\n",
    "    \n",
    "    df[\"total_transactions\"] = df[\"sequence number\"].apply(lambda node: count_unique_mempool_transactions(file_path, node))\n",
    "    \n",
    "    df[\"no. of transactions not finalised\"] = df[\"total_transactions\"] - df[\"No. of finalised transactions\"]\n",
    "    \n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.037159Z",
     "start_time": "2025-03-16T18:08:45.454731Z"
    }
   },
   "id": "e5426146017cc83d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path = 'src/simulator_events_log.txt'\n",
    "\n",
    "df = process_log_lines(file_path)\n",
    "df_sorted = df.sort_values(by='Timestamp of finalisation', ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.049655Z",
     "start_time": "2025-03-16T18:08:46.037575Z"
    }
   },
   "id": "241e6b522d963ec3",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "ADD INTERLEDGER CHECKS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8c23cf3429014b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Inter-Ledger Agreement Time: 1.0671428571428572\n"
     ]
    }
   ],
   "source": [
    "def calculate_inter_ledger_agreement_time(df):\n",
    "    df = df.sort_values(by='Timestamp of finalisation')\n",
    "    time_diffs = df['Timestamp of finalisation'].diff().dropna()\n",
    "    \n",
    "    return time_diffs.mean()\n",
    "\n",
    "avg_time = calculate_inter_ledger_agreement_time(df_sorted)\n",
    "print(f\"Average Inter-Ledger Agreement Time: {avg_time}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.058266Z",
     "start_time": "2025-03-16T18:08:46.053079Z"
    }
   },
   "id": "4f6a1ea63b72affc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  sequence number  Timestamp of finalisation  No. of finalised transactions  \\\n0               E                       9.90                              1   \n1               J                      12.92                              1   \n2               B                      13.91                              5   \n3               H                      14.08                              1   \n4               A                      14.87                              3   \n5               C                      15.41                              2   \n6               I                      17.01                              3   \n7               G                      17.37                              3   \n\n   no. of transactions not finalised  \n0                                 16  \n1                                 16  \n2                                 13  \n3                                 16  \n4                                 15  \n5                                 16  \n6                                 15  \n7                                 13  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence number</th>\n      <th>Timestamp of finalisation</th>\n      <th>No. of finalised transactions</th>\n      <th>no. of transactions not finalised</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E</td>\n      <td>9.90</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>J</td>\n      <td>12.92</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B</td>\n      <td>13.91</td>\n      <td>5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>H</td>\n      <td>14.08</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A</td>\n      <td>14.87</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>C</td>\n      <td>15.41</td>\n      <td>2</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I</td>\n      <td>17.01</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>G</td>\n      <td>17.37</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_experiment_df = df_sorted[[\n",
    "    \"sequence number\",\n",
    "    \"Timestamp of finalisation\",\n",
    "    \"No. of finalised transactions\",\n",
    "    \"no. of transactions not finalised\"\n",
    "]]\n",
    "\n",
    "display(final_experiment_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.078567Z",
     "start_time": "2025-03-16T18:08:46.059026Z"
    }
   },
   "id": "18a0b7d813327d2f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: 12.625\n"
     ]
    }
   ],
   "source": [
    "avg_difference = (final_experiment_df[\"no. of transactions not finalised\"] - final_experiment_df[\"No. of finalised transactions\"]).mean()\n",
    "\n",
    "print(f\"Average difference: {avg_difference}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.079444Z",
     "start_time": "2025-03-16T18:08:46.065655Z"
    }
   },
   "id": "a183fd7400e7d199",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of finalised transactions vs total: 13.67%\n"
     ]
    }
   ],
   "source": [
    "avg_finalised = final_experiment_df[\"No. of finalised transactions\"].mean()\n",
    "avg_total = (final_experiment_df[\"No. of finalised transactions\"] + \n",
    "             final_experiment_df[\"no. of transactions not finalised\"]).mean()\n",
    "\n",
    "finalised_percentage = (avg_finalised / avg_total) * 100 if avg_total != 0 else 0\n",
    "\n",
    "print(f\"Percentage of finalised transactions vs total: {finalised_percentage:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.080309Z",
     "start_time": "2025-03-16T18:08:46.068506Z"
    }
   },
   "id": "4632d0b4bbcc90a4",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ADD CHECKS FOR FIST EXTERNALIZE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0c1f9c295d8a94"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_transaction_count(line):\n",
    "    pattern = r\"transactions = \\{([^}]+)\\}\"\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        return set(re.findall(r\"Transaction ([a-fA-F0-9]+)\", match.group(1)))\n",
    "    return set()\n",
    "\n",
    "def get_timestamp(line):\n",
    "    pattern = r\"^\\d+\\.\\d+\"\n",
    "    match = re.match(pattern, line)\n",
    "    return float(match.group(0)) if match else None\n",
    "\n",
    "def get_node_name(line):\n",
    "    pattern = r\"Node ([A-Za-z0-9]+)\"\n",
    "    match = re.search(pattern, line)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def count_unique_mempool_transactions(file_path, node_number):\n",
    "    unique_transactions = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if f\"Node {node_number}\" in line and \"from mempool\" in line:\n",
    "                unique_transactions.update(re.findall(r\"Transaction ([a-fA-F0-9]+)\", line))\n",
    "    return len(unique_transactions)\n",
    "\n",
    "def process_log_lines(file_path):\n",
    "    # For each node, we keep track of its first externalize message, timestamp, and unique transactions.\n",
    "    node_data = defaultdict(lambda: {\n",
    "        \"Timestamp of finalisation\": None, \n",
    "        \"Finalised transactions\": set(),  \n",
    "        \"Externalize messages\": []  # Will store messages as a list, but only the first is used.\n",
    "    })\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        # Only consider lines that contain an externalize message\n",
    "        if 'appended SCPExternalize message to its storage and state' not in line:\n",
    "            continue\n",
    "        \n",
    "        node_name = get_node_name(line)\n",
    "        timestamp = get_timestamp(line)\n",
    "        transactions = get_transaction_count(line)\n",
    "        \n",
    "        if node_name:\n",
    "            # If no externalize message recorded yet for this node, then record this one.\n",
    "            if not node_data[node_name][\"Externalize messages\"]:\n",
    "                node_data[node_name][\"Timestamp of finalisation\"] = timestamp\n",
    "                node_data[node_name][\"Finalised transactions\"] = transactions\n",
    "                node_data[node_name][\"Externalize messages\"].append(line.strip())\n",
    "            # Otherwise, ignore subsequent messages.\n",
    "    \n",
    "    # Build DataFrame from the aggregated data.\n",
    "    df = pd.DataFrame.from_dict(node_data, orient='index')\n",
    "    df.index.name = \"node name\"\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Count the number of finalised transactions per node.\n",
    "    df[\"No. of finalised transactions\"] = df[\"Finalised transactions\"].apply(len)\n",
    "    \n",
    "    # For total transactions, count the unique transactions mined from the mempool for each node.\n",
    "    df[\"total_transactions\"] = df[\"node name\"].apply(lambda node: count_unique_mempool_transactions(file_path, node))\n",
    "    \n",
    "    # Calculate the number of transactions not finalised.\n",
    "    df[\"no. of transactions not finalised\"] = df[\"total_transactions\"] - df[\"No. of finalised transactions\"]\n",
    "    \n",
    "    # Replace the list of externalize messages with just the first message.\n",
    "    df[\"Externalize message\"] = df[\"Externalize messages\"].apply(lambda msgs: msgs[0] if msgs else None)\n",
    "    df.drop(columns=[\"Externalize messages\"], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# file_path = 'path/to/your/simulator_events_log.txt'\n",
    "# df = process_log_lines(file_path)\n",
    "# print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.080882Z",
     "start_time": "2025-03-16T18:08:46.074860Z"
    }
   },
   "id": "af25e26eb9c34743",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  node name  Timestamp of finalisation         Finalised transactions  \\\n0     Elsie                       9.90                     {ac47a4df}   \n1      John                      12.92                     {ac47a4df}   \n2       Bob                      13.91                     {f1d5943c}   \n3      Hank                      14.08                     {ac47a4df}   \n4     Alice                      14.87  {2110c21, f1d5943c, ac47a4df}   \n5     Carol                      15.41           {f1d5943c, ac47a4df}   \n6      Inez                      17.01  {2110c21, f1d5943c, ac47a4df}   \n7      Gwen                      17.37  {2110c21, f1d5943c, ac47a4df}   \n\n   No. of finalised transactions  total_transactions  \\\n0                              1                  17   \n1                              1                  17   \n2                              1                  18   \n3                              1                  17   \n4                              3                  18   \n5                              2                  18   \n6                              3                  18   \n7                              3                  16   \n\n   no. of transactions not finalised  \\\n0                                 16   \n1                                 16   \n2                                 17   \n3                                 16   \n4                                 15   \n5                                 16   \n6                                 15   \n7                                 13   \n\n                                 Externalize message  \n0  9.90 - NODE - INFO - Node Elsie appended SCPEx...  \n1  12.92 - NODE - INFO - Node John appended SCPEx...  \n2  13.91 - NODE - INFO - Node Bob appended SCPExt...  \n3  14.08 - NODE - INFO - Node Hank appended SCPEx...  \n4  14.87 - NODE - INFO - Node Alice appended SCPE...  \n5  15.41 - NODE - INFO - Node Carol appended SCPE...  \n6  17.01 - NODE - INFO - Node Inez appended SCPEx...  \n7  17.37 - NODE - INFO - Node Gwen appended SCPEx...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>node name</th>\n      <th>Timestamp of finalisation</th>\n      <th>Finalised transactions</th>\n      <th>No. of finalised transactions</th>\n      <th>total_transactions</th>\n      <th>no. of transactions not finalised</th>\n      <th>Externalize message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Elsie</td>\n      <td>9.90</td>\n      <td>{ac47a4df}</td>\n      <td>1</td>\n      <td>17</td>\n      <td>16</td>\n      <td>9.90 - NODE - INFO - Node Elsie appended SCPEx...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>John</td>\n      <td>12.92</td>\n      <td>{ac47a4df}</td>\n      <td>1</td>\n      <td>17</td>\n      <td>16</td>\n      <td>12.92 - NODE - INFO - Node John appended SCPEx...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bob</td>\n      <td>13.91</td>\n      <td>{f1d5943c}</td>\n      <td>1</td>\n      <td>18</td>\n      <td>17</td>\n      <td>13.91 - NODE - INFO - Node Bob appended SCPExt...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hank</td>\n      <td>14.08</td>\n      <td>{ac47a4df}</td>\n      <td>1</td>\n      <td>17</td>\n      <td>16</td>\n      <td>14.08 - NODE - INFO - Node Hank appended SCPEx...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alice</td>\n      <td>14.87</td>\n      <td>{2110c21, f1d5943c, ac47a4df}</td>\n      <td>3</td>\n      <td>18</td>\n      <td>15</td>\n      <td>14.87 - NODE - INFO - Node Alice appended SCPE...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Carol</td>\n      <td>15.41</td>\n      <td>{f1d5943c, ac47a4df}</td>\n      <td>2</td>\n      <td>18</td>\n      <td>16</td>\n      <td>15.41 - NODE - INFO - Node Carol appended SCPE...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Inez</td>\n      <td>17.01</td>\n      <td>{2110c21, f1d5943c, ac47a4df}</td>\n      <td>3</td>\n      <td>18</td>\n      <td>15</td>\n      <td>17.01 - NODE - INFO - Node Inez appended SCPEx...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Gwen</td>\n      <td>17.37</td>\n      <td>{2110c21, f1d5943c, ac47a4df}</td>\n      <td>3</td>\n      <td>16</td>\n      <td>13</td>\n      <td>17.37 - NODE - INFO - Node Gwen appended SCPEx...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = 'src/simulator_events_log.txt'\n",
    "\n",
    "df = process_log_lines(file_path)\n",
    "df_sorted = df.sort_values(by='Timestamp of finalisation', ascending=True)\n",
    "display(df_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.126547Z",
     "start_time": "2025-03-16T18:08:46.077218Z"
    }
   },
   "id": "cdd71640afdea154",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Elsie has the exact same transactions as:\n",
      "  - John\n",
      "  - Hank\n",
      "Node John has the exact same transactions as:\n",
      "  - Hank\n",
      "Node Alice has the exact same transactions as:\n",
      "  - Inez\n",
      "  - Gwen\n",
      "Node Inez has the exact same transactions as:\n",
      "  - Gwen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_exact_matches(df):\n",
    "    # Convert 'Finalised transactions' to sets\n",
    "    def convert_to_set(val):\n",
    "        if isinstance(val, str):\n",
    "            return eval(val)  # Convert string representation to set\n",
    "        elif isinstance(val, set):\n",
    "            return val  # If it's already a set, return it\n",
    "        else:\n",
    "            return set()  # In case of any unexpected format\n",
    "    \n",
    "    # Convert the 'Finalised transactions' column to sets\n",
    "    df['Finalised transactions'] = df['Finalised transactions'].apply(convert_to_set)\n",
    "    \n",
    "    # Create a dictionary to store matches\n",
    "    matches = {}\n",
    "    \n",
    "    # Iterate through each row and compare 'Finalised transactions' with every other row\n",
    "    for i, row_i in df.iterrows():\n",
    "        node_i = row_i[\"node name\"]\n",
    "        transactions_i = row_i[\"Finalised transactions\"]\n",
    "        \n",
    "        for j, row_j in df.iterrows():\n",
    "            if i < j:  # Only compare each pair once\n",
    "                node_j = row_j[\"node name\"]\n",
    "                transactions_j = row_j[\"Finalised transactions\"]\n",
    "                \n",
    "                # Check if the transactions are exactly the same (size and content)\n",
    "                if len(transactions_i) == len(transactions_j) and transactions_i == transactions_j:\n",
    "                    if node_i not in matches:\n",
    "                        matches[node_i] = []\n",
    "                    matches[node_i].append(node_j)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Assuming df_sorted is your DataFrame\n",
    "matches = check_exact_matches(df_sorted)\n",
    "\n",
    "# Print the matches\n",
    "for node, matched_nodes in matches.items():\n",
    "    print(f\"Node {node} has the exact same transactions as:\")\n",
    "    for matched_node in matched_nodes:\n",
    "        print(f\"  - {matched_node}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.136242Z",
     "start_time": "2025-03-16T18:08:46.092985Z"
    }
   },
   "id": "3fc362ca71498bf7",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d481cb0eaa7e5dae"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching transactions for node Elsie:\n",
      "  - John: 1 matching transactions\n",
      "  - Bob: 0 matching transactions\n",
      "  - Hank: 1 matching transactions\n",
      "  - Alice: 1 matching transactions\n",
      "  - Carol: 1 matching transactions\n",
      "  - Inez: 1 matching transactions\n",
      "  - Gwen: 1 matching transactions\n",
      "Matching transactions for node John:\n",
      "  - Elsie: 1 matching transactions\n",
      "  - Bob: 0 matching transactions\n",
      "  - Hank: 1 matching transactions\n",
      "  - Alice: 1 matching transactions\n",
      "  - Carol: 1 matching transactions\n",
      "  - Inez: 1 matching transactions\n",
      "  - Gwen: 1 matching transactions\n",
      "Matching transactions for node Bob:\n",
      "  - Elsie: 0 matching transactions\n",
      "  - John: 0 matching transactions\n",
      "  - Hank: 0 matching transactions\n",
      "  - Alice: 1 matching transactions\n",
      "  - Carol: 1 matching transactions\n",
      "  - Inez: 1 matching transactions\n",
      "  - Gwen: 1 matching transactions\n",
      "Matching transactions for node Hank:\n",
      "  - Elsie: 1 matching transactions\n",
      "  - John: 1 matching transactions\n",
      "  - Bob: 0 matching transactions\n",
      "  - Alice: 1 matching transactions\n",
      "  - Carol: 1 matching transactions\n",
      "  - Inez: 1 matching transactions\n",
      "  - Gwen: 1 matching transactions\n",
      "Matching transactions for node Alice:\n",
      "  - Elsie: 1 matching transactions\n",
      "  - John: 1 matching transactions\n",
      "  - Bob: 1 matching transactions\n",
      "  - Hank: 1 matching transactions\n",
      "  - Carol: 2 matching transactions\n",
      "  - Inez: 3 matching transactions\n",
      "  - Gwen: 3 matching transactions\n",
      "Matching transactions for node Carol:\n",
      "  - Elsie: 1 matching transactions\n",
      "  - John: 1 matching transactions\n",
      "  - Bob: 1 matching transactions\n",
      "  - Hank: 1 matching transactions\n",
      "  - Alice: 2 matching transactions\n",
      "  - Inez: 2 matching transactions\n",
      "  - Gwen: 2 matching transactions\n",
      "Matching transactions for node Inez:\n",
      "  - Elsie: 1 matching transactions\n",
      "  - John: 1 matching transactions\n",
      "  - Bob: 1 matching transactions\n",
      "  - Hank: 1 matching transactions\n",
      "  - Alice: 3 matching transactions\n",
      "  - Carol: 2 matching transactions\n",
      "  - Gwen: 3 matching transactions\n",
      "Matching transactions for node Gwen:\n",
      "  - Elsie: 1 matching transactions\n",
      "  - John: 1 matching transactions\n",
      "  - Bob: 1 matching transactions\n",
      "  - Hank: 1 matching transactions\n",
      "  - Alice: 3 matching transactions\n",
      "  - Carol: 2 matching transactions\n",
      "  - Inez: 3 matching transactions\n"
     ]
    }
   ],
   "source": [
    "def compute_matching_transactions(df):\n",
    "    matching_counts = {}\n",
    "\n",
    "    # Compare the transactions of each node with the other nodes\n",
    "    for i, row_i in df.iterrows():\n",
    "        node_i = row_i[\"node name\"]\n",
    "        transactions_i = row_i[\"Finalised transactions\"]\n",
    "        \n",
    "        matching_transactions = {}\n",
    "\n",
    "        for j, row_j in df.iterrows():\n",
    "            if i != j:  # Don't compare the node with itself\n",
    "                node_j = row_j[\"node name\"]\n",
    "                transactions_j = row_j[\"Finalised transactions\"]\n",
    "                \n",
    "                # Find common transactions between node_i and node_j\n",
    "                common_transactions = transactions_i.intersection(transactions_j)\n",
    "                matching_transactions[node_j] = len(common_transactions)\n",
    "\n",
    "        matching_counts[node_i] = matching_transactions\n",
    "\n",
    "    return matching_counts\n",
    "\n",
    "# Get the matching transaction counts\n",
    "matching_counts = compute_matching_transactions(df)\n",
    "\n",
    "# Display the results\n",
    "for node, matches in matching_counts.items():\n",
    "    print(f\"Matching transactions for node {node}:\")\n",
    "    for other_node, count in matches.items():\n",
    "        print(f\"  - {other_node}: {count} matching transactions\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.152380Z",
     "start_time": "2025-03-16T18:08:46.098849Z"
    }
   },
   "id": "4e850655160fc33a",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GIVEN MATCHING TRANSACTIONS, NOW FURTHER ANALYSIS USING QUORUM SETS AND THRESHOLD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a6fd438991b75d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "QUORUM SETS AND THRESHOLD USED IN SIMULATOR FOR ROUND OF LUNHC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d22d43dd85ee17b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "quorum_sets = {\n",
    "                    \"Alice\": [\"Bob\", \"Carol\", \"Dave\"],\n",
    "                    \"Bob\": [\"Alice\", \"Carol\", \"Dave\"],\n",
    "                    \"Carol\": [\"Alice\", \"Bob\", \"Dave\"],\n",
    "                    \"Dave\": [\"Alice\", \"Bob\", \"Carol\"],\n",
    "                    \"Elsie\": [\"Alice\", \"Bob\", \"Carol\", \"Dave\"],\n",
    "                    \"Fred\": [\"Alice\", \"Bob\", \"Carol\", \"Dave\"],\n",
    "                    \"Gwen\": [\"Alice\", \"Bob\", \"Carol\", \"Dave\"],\n",
    "                    \"Hank\": [\"Alice\", \"Bob\", \"Carol\", \"Dave\"],\n",
    "                    \"Inez\": [\"Elsie\", \"Fred\", \"Gwen\", \"Hank\"],\n",
    "                    \"John\": [\"Elsie\", \"Fred\", \"Gwen\", \"Hank\"]\n",
    "}\n",
    "\n",
    "quorum_thresholds = {\n",
    "                    \"Alice\": 2, \"Bob\": 2, \"Carol\": 2, \"Dave\": 2,  # 2 out of 3 → 67%\n",
    "                    \"Elsie\": 2, \"Fred\": 2, \"Gwen\": 2, \"Hank\": 2,  # 2 out of 4 → 50%\n",
    "                    \"Inez\": 2, \"John\": 2  # 2 out of 4 → 50%\n",
    "}\n",
    "top_tier_nodes = [\"Alice\", \"Bob\", \"Carol\", \"Dave\"] # each depends on two of its neighbors for a quorum\n",
    "middle_tier_nodes = [\"Elsie\", \"Fred\", \"Gwen\", \"Hank\"] # each depends on any two members of the top tier\n",
    "bottom_tier_nodes = [\"Inez\", \"John\"] # each depends on any two members of the middle tier.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.153036Z",
     "start_time": "2025-03-16T18:08:46.102789Z"
    }
   },
   "id": "148017fdbabe7109",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_matching_transactions_by_tiers(df, quorum_sets, quorum_thresholds, top_tier_nodes, middle_tier_nodes, bottom_tier_nodes):\n",
    "    matching_counts = {}\n",
    "\n",
    "    # Iterate over the nodes in the DataFrame\n",
    "    for i, row_i in df.iterrows():\n",
    "        node_i = row_i[\"node name\"]\n",
    "        transactions_i = row_i[\"Finalised transactions\"]\n",
    "\n",
    "        matching_transactions = {\n",
    "            \"total\": len(transactions_i),  # Total transactions for node_i\n",
    "            \"top_tier\": {},\n",
    "            \"middle_tier\": {},\n",
    "            \"bottom_tier\": {}\n",
    "        }\n",
    "\n",
    "        # Compare node_i's transactions with others in their respective tiers\n",
    "        for j, row_j in df.iterrows():\n",
    "            if i != j:  # Don't compare the node with itself\n",
    "                node_j = row_j[\"node name\"]\n",
    "                transactions_j = row_j[\"Finalised transactions\"]\n",
    "\n",
    "                # Find common transactions between node_i and node_j\n",
    "                common_transactions = transactions_i.intersection(transactions_j)\n",
    "                match_count = len(common_transactions)\n",
    "\n",
    "                # Determine the tier for node_j based on its position in the quorum_sets\n",
    "                if node_j in quorum_sets[node_i]:\n",
    "                    if node_j in top_tier_nodes:\n",
    "                        matching_transactions[\"top_tier\"][node_j] = match_count\n",
    "                    elif node_j in middle_tier_nodes:\n",
    "                        matching_transactions[\"middle_tier\"][node_j] = match_count\n",
    "                    elif node_j in bottom_tier_nodes:\n",
    "                        matching_transactions[\"bottom_tier\"][node_j] = match_count\n",
    "\n",
    "        matching_counts[node_i] = matching_transactions\n",
    "\n",
    "    return matching_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.153958Z",
     "start_time": "2025-03-16T18:08:46.106185Z"
    }
   },
   "id": "430f988ead571082",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching transactions for node Elsie in tier Middle-tier(Total: 1 transactions):\n",
      "  - Top-tier matches:\n",
      "    * Bob: 0 matching transactions\n",
      "    * Alice: 1 matching transactions\n",
      "    * Carol: 1 matching transactions\n",
      "  - Middle-tier matches:\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node John in tier Bottom-tier(Total: 1 transactions):\n",
      "  - Top-tier matches:\n",
      "  - Middle-tier matches:\n",
      "    * Elsie: 1 matching transactions\n",
      "    * Hank: 1 matching transactions\n",
      "    * Gwen: 1 matching transactions\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node Bob in tier Top-tier(Total: 1 transactions):\n",
      "  - Top-tier matches:\n",
      "    * Alice: 1 matching transactions\n",
      "    * Carol: 1 matching transactions\n",
      "  - Middle-tier matches:\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node Hank in tier Middle-tier(Total: 1 transactions):\n",
      "  - Top-tier matches:\n",
      "    * Bob: 0 matching transactions\n",
      "    * Alice: 1 matching transactions\n",
      "    * Carol: 1 matching transactions\n",
      "  - Middle-tier matches:\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node Alice in tier Top-tier(Total: 3 transactions):\n",
      "  - Top-tier matches:\n",
      "    * Bob: 1 matching transactions\n",
      "    * Carol: 2 matching transactions\n",
      "  - Middle-tier matches:\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node Carol in tier Top-tier(Total: 2 transactions):\n",
      "  - Top-tier matches:\n",
      "    * Bob: 1 matching transactions\n",
      "    * Alice: 2 matching transactions\n",
      "  - Middle-tier matches:\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node Inez in tier Bottom-tier(Total: 3 transactions):\n",
      "  - Top-tier matches:\n",
      "  - Middle-tier matches:\n",
      "    * Elsie: 1 matching transactions\n",
      "    * Hank: 1 matching transactions\n",
      "    * Gwen: 3 matching transactions\n",
      "  - Bottom-tier matches:\n",
      "\n",
      "Matching transactions for node Gwen in tier Middle-tier(Total: 3 transactions):\n",
      "  - Top-tier matches:\n",
      "    * Bob: 1 matching transactions\n",
      "    * Alice: 3 matching transactions\n",
      "    * Carol: 2 matching transactions\n",
      "  - Middle-tier matches:\n",
      "  - Bottom-tier matches:\n"
     ]
    }
   ],
   "source": [
    "matching_counts = compute_matching_transactions_by_tiers(df, quorum_sets, quorum_thresholds, top_tier_nodes, middle_tier_nodes, bottom_tier_nodes)\n",
    "\n",
    "# Display the results\n",
    "for node, matches in matching_counts.items():\n",
    "    if node in top_tier_nodes:\n",
    "        tier = \"Top-tier\"\n",
    "    elif node in middle_tier_nodes:\n",
    "        tier = \"Middle-tier\"\n",
    "    elif node in bottom_tier_nodes:\n",
    "        tier = \"Bottom-tier\"\n",
    "    else:\n",
    "        tier = \"Unknown-tier\"\n",
    "    # Print the node, its tier, and total transactions before showing matches\n",
    "    print(f\"Matching transactions for node {node} in tier {tier}(Total: {matches['total']} transactions):\")\n",
    "    \n",
    "    print(f\"  - Top-tier matches:\")\n",
    "    for top_node, count in matches[\"top_tier\"].items():\n",
    "        print(f\"    * {top_node}: {count} matching transactions\")\n",
    "    \n",
    "    print(f\"  - Middle-tier matches:\")\n",
    "    for middle_node, count in matches[\"middle_tier\"].items():\n",
    "        print(f\"    * {middle_node}: {count} matching transactions\")\n",
    "    \n",
    "    print(f\"  - Bottom-tier matches:\")\n",
    "    for bottom_node, count in matches[\"bottom_tier\"].items():\n",
    "        print(f\"    * {bottom_node}: {count} matching transactions\")\n",
    "    \n",
    "    print()  # For readability between node results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.154706Z",
     "start_time": "2025-03-16T18:08:46.112360Z"
    }
   },
   "id": "93c911cb671f27fa",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DELAYS IN EXTERNALISATION FOR LEAD NODES VS OUTER NODES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677f3d95cb7b018d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_finalization_delay(df, top_tier, middle_tier, bottom_tier):\n",
    "    \"\"\"\n",
    "    Analyzes the delay in finalization times across the three-tier structure.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing node names and finalization timestamps.\n",
    "        top_tier (list): List of top-tier node names.\n",
    "        middle_tier (list): List of middle-tier node names.\n",
    "        bottom_tier (list): List of bottom-tier node names.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains average finalization times for each tier and delays between them.\n",
    "    \"\"\"\n",
    "    top_times = df[df[\"node name\"].isin(top_tier)][\"Timestamp of finalisation\"]\n",
    "    middle_times = df[df[\"node name\"].isin(middle_tier)][\"Timestamp of finalisation\"]\n",
    "    bottom_times = df[df[\"node name\"].isin(bottom_tier)][\"Timestamp of finalisation\"]\n",
    "\n",
    "    top_avg = top_times.mean()\n",
    "    middle_avg = middle_times.mean()\n",
    "    bottom_avg = bottom_times.mean()\n",
    "\n",
    "    delay_top_to_middle = middle_avg - top_avg\n",
    "    delay_middle_to_bottom = bottom_avg - middle_avg\n",
    "    delay_top_to_bottom = bottom_avg - top_avg\n",
    "\n",
    "    return {\n",
    "        \"top_avg_finalization_time\": top_avg,\n",
    "        \"middle_avg_finalization_time\": middle_avg,\n",
    "        \"bottom_avg_finalization_time\": bottom_avg,\n",
    "        \"delay_top_to_middle\": delay_top_to_middle,\n",
    "        \"delay_middle_to_bottom\": delay_middle_to_bottom,\n",
    "        \"delay_top_to_bottom\": delay_top_to_bottom\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.187093Z",
     "start_time": "2025-03-16T18:08:46.117671Z"
    }
   },
   "id": "6f75fec0cf1a9395",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalization Delay Analysis: {'top_avg_finalization_time': 14.729999999999999, 'middle_avg_finalization_time': 13.783333333333333, 'bottom_avg_finalization_time': 14.965, 'delay_top_to_middle': -0.9466666666666654, 'delay_middle_to_bottom': 1.1816666666666666, 'delay_top_to_bottom': 0.2350000000000012}\n"
     ]
    }
   ],
   "source": [
    "# Define groups\n",
    "top_tier = [\"Alice\", \"Bob\", \"Carol\", \"Dave\"] # each depends on two of its neighbors for a quorum\n",
    "middle_tier = [\"Elsie\", \"Fred\", \"Gwen\", \"Hank\"] # each depends on any two members of the top tier\n",
    "bottom_tier = [\"Inez\", \"John\"] # each depends on any two members of the middle tier.\n",
    "\n",
    "# Run analyses\n",
    "finalization_delay = analyze_finalization_delay(df, top_tier, middle_tier, bottom_tier)\n",
    "\n",
    "# Print results\n",
    "print(\"Finalization Delay Analysis:\", finalization_delay)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.244270Z",
     "start_time": "2025-03-16T18:08:46.122980Z"
    }
   },
   "id": "b0666bac52e735c7",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TRANSACTION PROPAGATION IN NODES WITH NO LINKS (OR WEAK LINKS THROUGH PEERS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a983790fd81e94b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "def transaction_overlap(df, group1, group2, group3):\n",
    "    \"\"\"\n",
    "    Measures the percentage of matching transactions between three groups of nodes.\n",
    "    Computes overlap separately for (g1-g2), (g1-g3), (g2-g3), and all three together.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing nodes and finalized transactions.\n",
    "        group1 (list): First group of nodes (e.g., top tier).\n",
    "        group2 (list): Second group of nodes (e.g., middle tier).\n",
    "        group3 (list): Third group of nodes (e.g., bottom tier).\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains average transaction match percentages for each pair of groups\n",
    "              and overall across all three groups.\n",
    "    \"\"\"\n",
    "    def compute_overlap(nodes1, nodes2):\n",
    "        \"\"\"Helper function to compute overlap between two sets of nodes.\"\"\"\n",
    "        total_pairs = 0\n",
    "        total_match_percentage = 0\n",
    "\n",
    "        for (node1, txs1), (node2, txs2) in combinations(\n",
    "            zip(df[\"node name\"], df[\"Finalised transactions\"]), 2\n",
    "        ):\n",
    "             # cjecl that one noed is in group 'nodes1' and the other is in 'nodes2', not that they are part of the same group\n",
    "            if node1 in nodes1 and node2 in nodes2:\n",
    "                total_pairs += 1\n",
    "                match_count = len(set(txs1).intersection(set(txs2))) # compare each matching transaction\n",
    "                total_transactions = len(set(txs1).union(set(txs2))) # total transactions in both externalised values\n",
    "                match_percentage = (match_count / total_transactions) if total_transactions else 0\n",
    "                total_match_percentage += match_percentage\n",
    "\n",
    "        return total_match_percentage / total_pairs if total_pairs else 0\n",
    "\n",
    "    # Compute pairwise overlaps\n",
    "    g1_g2_overlap = compute_overlap(group1, group2)\n",
    "    g1_g3_overlap = compute_overlap(group1, group3)\n",
    "    g2_g3_overlap = compute_overlap(group2, group3)\n",
    "\n",
    "    # Compute overall overlap across all three groups\n",
    "    all_groups_overlap = compute_overlap(group1 + group2, group3)\n",
    "\n",
    "    return {\n",
    "        \"Top-Middle Overlap\": g1_g2_overlap,\n",
    "        \"Top-Bottom Overlap\": g1_g3_overlap,\n",
    "        \"Middle-Bottom Overlap\": g2_g3_overlap,\n",
    "        \"Overall Three-Group Overlap\": all_groups_overlap\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.245887Z",
     "start_time": "2025-03-16T18:08:46.128533Z"
    }
   },
   "id": "463579219e3a4045",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Propagation Analysis: {'Top-Middle Overlap': 0.5, 'Top-Bottom Overlap': 0.6666666666666666, 'Middle-Bottom Overlap': 0.5555555555555555, 'Overall Three-Group Overlap': 0.611111111111111}\n"
     ]
    }
   ],
   "source": [
    "propagation_analysis = transaction_overlap(df, top_tier, middle_tier, bottom_tier)\n",
    "print(\"Transaction Propagation Analysis:\", propagation_analysis)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.255798Z",
     "start_time": "2025-03-16T18:08:46.130626Z"
    }
   },
   "id": "5b1eab03754a5ab8",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EFFECT OF LOWER QUORUM THRESHOLD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fc504379c220a6a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def analyze_threshold_effect(df, quorum_thresholds):\n",
    "    \"\"\"\n",
    "    Analyzes how different quorum thresholds affect transaction agreement.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing nodes and finalized transactions.\n",
    "        quorum_thresholds (dict): A dictionary mapping nodes to their quorum thresholds.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains statistics on transaction agreement and threshold impact.\n",
    "    \"\"\"\n",
    "    unique_transactions_per_node = df[\"Finalised transactions\"].apply(len)\n",
    "    avg_transactions = unique_transactions_per_node.mean()\n",
    "    \n",
    "    threshold_agreement = {\n",
    "        node: {\n",
    "            \"threshold\": quorum_thresholds[node],\n",
    "            \"transactions_finalized\": df[df[\"node name\"] == node][\"No. of finalised transactions\"].values[0]\n",
    "        }\n",
    "        for node in quorum_thresholds\n",
    "    }\n",
    "    threshold_df = pd.DataFrame(threshold_agreement)\n",
    "\n",
    "    return  avg_transactions, threshold_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.264035Z",
     "start_time": "2025-03-16T18:08:46.135587Z"
    }
   },
   "id": "a423c2f016659139",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m avg_txs, threshold_df \u001B[38;5;241m=\u001B[39m \u001B[43manalyze_threshold_effect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquorum_thresholds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThreshold Effect Analysis:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAverage_transactions_finalized\u001B[39m\u001B[38;5;124m\"\u001B[39m, avg_txs)\n",
      "Cell \u001B[0;32mIn[19], line 15\u001B[0m, in \u001B[0;36manalyze_threshold_effect\u001B[0;34m(df, quorum_thresholds)\u001B[0m\n\u001B[1;32m     12\u001B[0m unique_transactions_per_node \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinalised transactions\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28mlen\u001B[39m)\n\u001B[1;32m     13\u001B[0m avg_transactions \u001B[38;5;241m=\u001B[39m unique_transactions_per_node\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m---> 15\u001B[0m threshold_agreement \u001B[38;5;241m=\u001B[39m \u001B[43m{\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreshold\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquorum_thresholds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtransactions_finalized\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnode name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNo. of finalised transactions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mquorum_thresholds\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m\u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m     22\u001B[0m threshold_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(threshold_agreement)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m  avg_transactions, threshold_df\n",
      "Cell \u001B[0;32mIn[19], line 18\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     12\u001B[0m unique_transactions_per_node \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinalised transactions\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28mlen\u001B[39m)\n\u001B[1;32m     13\u001B[0m avg_transactions \u001B[38;5;241m=\u001B[39m unique_transactions_per_node\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     15\u001B[0m threshold_agreement \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     16\u001B[0m     node: {\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthreshold\u001B[39m\u001B[38;5;124m\"\u001B[39m: quorum_thresholds[node],\n\u001B[0;32m---> 18\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransactions_finalized\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnode name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNo. of finalised transactions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     19\u001B[0m     }\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m quorum_thresholds\n\u001B[1;32m     21\u001B[0m }\n\u001B[1;32m     22\u001B[0m threshold_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(threshold_agreement)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m  avg_transactions, threshold_df\n",
      "\u001B[0;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "avg_txs, threshold_df = analyze_threshold_effect(df, quorum_thresholds)\n",
    "print(\"Threshold Effect Analysis:\")\n",
    "print(\"Average_transactions_finalized\", avg_txs)\n",
    "display(threshold_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-16T18:08:46.313482Z",
     "start_time": "2025-03-16T18:08:46.139557Z"
    }
   },
   "id": "72ed443868854462",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-16T18:08:46.259077Z"
    }
   },
   "id": "9a5f2cb9b6b2b915",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONCLUSIONS FROM DATA ANALYSIS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be18382cf94f95ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalization Delays:\n",
    "\n",
    "The Top tier finalized transactions the earliest on average, but the delay between Top-Middle and Middle-Bottom is relatively small.\n",
    "Delay between Top and Bottom being negative (-7.7) suggests that nodes in the Top tier finalize faster than those in the Bottom tier.\n",
    "The asynchronous behavior of the simulator means there is no global synchronization of node actions, which likely results in these delays. Synchronization points during the real SCP implementation are crucial to maintain consistency across nodes at different tiers, but the simulator misses this aspect.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2829de33b1e58fa9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transaction Overlap:\n",
    "\n",
    "The low transaction overlap indicates that transactions are not propagated efficiently between the tiers. In a real-world SCP implementation, once a value is finalized in one tier, it should propagate to the other tiers effectively to ensure a quicker consensus process. The simulator’s lack of synchronization likely hinders this propagation.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36cc166fdf3a320c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Effect of Quorum Thresholds:\n",
    "\n",
    "The large variation in finalized transactions (1 to 61) indicates that quorum thresholds are having inconsistent effects across nodes. Some nodes seem to finalize transactions quicker than others, but overall, the average finalized transactions (26) indicate some nodes are not able to meet the quorum efficiently, possibly because lower thresholds result in early externalization without proper coordination"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c51d33579699477c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-16T18:08:46.259810Z"
    }
   },
   "id": "e5e408158a5b496f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
